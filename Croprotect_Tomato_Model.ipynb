{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bzChom-4HXf","outputId":"6c83cb27-8021-424e-f6e2-ed7019a9599f","executionInfo":{"status":"ok","timestamp":1708359261251,"user_tz":-330,"elapsed":90761,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"79s-Fd4Y6j8f","executionInfo":{"status":"ok","timestamp":1708359261253,"user_tz":-330,"elapsed":23,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[],"source":["dataset_path = '/content/drive/MyDrive/Data Science and Analytics mini project/PlantVillage/PlantVillage/Tomato'"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"oorjqGtO5jTl","executionInfo":{"status":"ok","timestamp":1708359261254,"user_tz":-330,"elapsed":17,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[],"source":["import os\n","from os import listdir\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ePjQkPiv5mp2","executionInfo":{"status":"ok","timestamp":1708359263868,"user_tz":-330,"elapsed":2629,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import tensorflow.keras as keras\n","import re\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2j-2wTxc5p_r","outputId":"c5e29e53-0d17-462f-a692-eb2314a62ca5","executionInfo":{"status":"ok","timestamp":1708359899045,"user_tz":-330,"elapsed":462928,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset split into training and validation sets.\n"]}],"source":["import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","\n","# Define the source directory containing your dataset\n","source_dir = dataset_path\n","\n","# Define the destination directories for training and validation data\n","train_dir = \"tomato/train\"\n","valid_dir = \"tomato/valid\"\n","\n","# Create the destination directories if they don't exist\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(valid_dir, exist_ok=True)\n","\n","# Get a list of class folders in the source directory\n","class_folders = os.listdir(source_dir)\n","\n","# Define the ratio of data to put in the validation set (e.g., 20%)\n","validation_ratio = 0.2\n","\n","# Loop through each class folder and split the data\n","for class_folder in class_folders:\n","    class_path = os.path.join(source_dir, class_folder)\n","    if os.path.isdir(class_path):\n","        images = os.listdir(class_path)\n","        # Split the images into training and validation sets\n","        train_images, valid_images = train_test_split(images, test_size=validation_ratio, random_state=42)\n","\n","        # Create destination directories for this class in the training and validation sets\n","        train_class_dir = os.path.join(train_dir, class_folder)\n","        valid_class_dir = os.path.join(valid_dir, class_folder)\n","        os.makedirs(train_class_dir, exist_ok=True)\n","        os.makedirs(valid_class_dir, exist_ok=True)\n","\n","        # Copy training images\n","        for image in train_images:\n","            source_image_path = os.path.join(class_path, image)\n","            dest_image_path = os.path.join(train_class_dir, image)\n","            shutil.copy(source_image_path, dest_image_path)\n","\n","        # Copy validation images\n","        for image in valid_images:\n","            source_image_path = os.path.join(class_path, image)\n","            dest_image_path = os.path.join(valid_class_dir, image)\n","            shutil.copy(source_image_path, dest_image_path)\n","\n","print(\"Dataset split into training and validation sets.\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_xsT6ZuC5tDq","outputId":"4d69fb6e-0033-4f1f-f30e-e2d6b1bb8f93","executionInfo":{"status":"ok","timestamp":1708359899046,"user_tz":-330,"elapsed":10,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of files in the training directory: 12805\n","Number of files in the validation directory: 3207\n"]}],"source":["TRAIN_DIR = \"tomato/train\"\n","VALID_DIR = \"tomato/valid\"\n","def count_files_in_directory(directory):\n","    total_files = 0\n","    for root, dirs, files in os.walk(directory):\n","        total_files += len(files)\n","    return total_files\n","\n","num_train_files = count_files_in_directory(TRAIN_DIR)\n","num_valid_files = count_files_in_directory(VALID_DIR)\n","\n","print(\"Number of files in the training directory:\", num_train_files)\n","print(\"Number of files in the validation directory:\", num_valid_files)\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TdnCPI0B5vgm","outputId":"a1f14563-d2fe-4e40-87ca-40d080fcdc8d","executionInfo":{"status":"ok","timestamp":1708359899046,"user_tz":-330,"elapsed":7,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes in the training directory: 10\n","Class names in the training directory:\n","Tomato_Spider_mites_Two_spotted_spider_mite\n","Tomato__Tomato_YellowLeaf__Curl_Virus\n","Tomato_Septoria_leaf_spot\n","Tomato_Late_blight\n","Tomato__Target_Spot\n","Tomato_healthy\n","Tomato__Tomato_mosaic_virus\n","Tomato_Early_blight\n","Tomato_Leaf_Mold\n","Tomato_Bacterial_spot\n"]}],"source":["TRAIN_DIR = \"tomato/train\"\n","\n","def get_classes_and_count(directory):\n","    classes = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n","    return classes, len(classes)\n","\n","class_names, CLASS_NUMS = get_classes_and_count(TRAIN_DIR)\n","\n","print(\"Number of classes in the training directory:\", CLASS_NUMS)\n","print(\"Class names in the training directory:\")\n","for class_name in class_names:\n","    print(class_name)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpt7ySGo5x-j","outputId":"94175b1b-a28d-4352-dba2-5672433b670d","executionInfo":{"status":"ok","timestamp":1708361667892,"user_tz":-330,"elapsed":1740527,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 12805 images belonging to 10 classes.\n","Found 3206 images belonging to 10 classes.\n","Epoch 1/7\n","401/401 [==============================] - 282s 594ms/step - loss: 0.8429 - accuracy: 0.7439 - val_loss: 14.5076 - val_accuracy: 0.1192\n","Epoch 2/7\n","401/401 [==============================] - 235s 585ms/step - loss: 0.3597 - accuracy: 0.8907 - val_loss: 4.5910 - val_accuracy: 0.2832\n","Epoch 3/7\n","401/401 [==============================] - 247s 615ms/step - loss: 0.2454 - accuracy: 0.9220 - val_loss: 0.6955 - val_accuracy: 0.8344\n","Epoch 4/7\n","401/401 [==============================] - 236s 589ms/step - loss: 0.1954 - accuracy: 0.9362 - val_loss: 1.6815 - val_accuracy: 0.7227\n","Epoch 5/7\n","401/401 [==============================] - 235s 585ms/step - loss: 0.1899 - accuracy: 0.9410 - val_loss: 0.5834 - val_accuracy: 0.8656\n","Epoch 6/7\n","401/401 [==============================] - 246s 613ms/step - loss: 0.1743 - accuracy: 0.9443 - val_loss: 0.3354 - val_accuracy: 0.9021\n","Epoch 7/7\n","401/401 [==============================] - 236s 588ms/step - loss: 0.1546 - accuracy: 0.9498 - val_loss: 0.7056 - val_accuracy: 0.8518\n"]}],"source":["import os\n","import shutil\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import ResNet50  # Example pre-trained model\n","\n","# Define directories and constants\n","source_dir = dataset_path\n","train_dir = \"tomato/train\"\n","valid_dir = \"tomato/valid\"\n","BATCH_SIZE = 32\n","IMAGE_SHAPE = (224, 224)\n","numEPOCHS = 7\n","\n","# Data Augmentation\n","training_aug = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","testing_aug = ImageDataGenerator(rescale=1./255.0)\n","\n","# Load and preprocess data\n","training_data = training_aug.flow_from_directory(\n","    train_dir,\n","    batch_size=BATCH_SIZE,\n","    target_size=IMAGE_SHAPE,\n","    shuffle=True,\n","    class_mode='categorical')\n","\n","testing_data = testing_aug.flow_from_directory(\n","    valid_dir,\n","    batch_size=BATCH_SIZE,\n","    target_size=IMAGE_SHAPE,\n","    class_mode='categorical')\n","\n","# Define and compile the model\n","base_model = ResNet50(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(224, 224, 3)\n",")\n","\n","model = keras.Sequential([\n","    base_model,\n","    keras.layers.GlobalAveragePooling2D(),\n","    keras.layers.Dense(256, activation='relu'),\n","    keras.layers.Dropout(0.5),\n","    keras.layers.Dense(CLASS_NUMS, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer='adam',\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Training with early stopping\n","early_stopping = keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    restore_best_weights=True\n",")\n","\n","history = model.fit(\n","    training_data,\n","    validation_data=testing_data,\n","    epochs=numEPOCHS,\n","    steps_per_epoch=len(training_data),\n","    validation_steps=len(testing_data),\n","    callbacks=[early_stopping]\n",")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"oZLyQK4cGGBY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a14c1158-3ec6-40a7-d1ae-1a43b9035f0d","executionInfo":{"status":"ok","timestamp":1708363397941,"user_tz":-330,"elapsed":1713646,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 12805 images belonging to 10 classes.\n","Found 3206 images belonging to 10 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 5s 0us/step\n","Epoch 1/7\n","401/401 [==============================] - 265s 552ms/step - loss: 0.6754 - accuracy: 0.7991 - val_loss: 1.8171 - val_accuracy: 0.6004 - lr: 0.0010\n","Epoch 2/7\n","401/401 [==============================] - 215s 536ms/step - loss: 0.3427 - accuracy: 0.8970 - val_loss: 0.3507 - val_accuracy: 0.9011 - lr: 0.0010\n","Epoch 3/7\n","401/401 [==============================] - 218s 543ms/step - loss: 0.2408 - accuracy: 0.9239 - val_loss: 0.3629 - val_accuracy: 0.8930 - lr: 0.0010\n","Epoch 4/7\n","401/401 [==============================] - 219s 546ms/step - loss: 0.2056 - accuracy: 0.9365 - val_loss: 0.3753 - val_accuracy: 0.8899 - lr: 0.0010\n","Epoch 5/7\n","401/401 [==============================] - 219s 547ms/step - loss: 0.1651 - accuracy: 0.9480 - val_loss: 0.8235 - val_accuracy: 0.8001 - lr: 0.0010\n","Epoch 6/7\n","401/401 [==============================] - 219s 545ms/step - loss: 0.1675 - accuracy: 0.9459 - val_loss: 0.2206 - val_accuracy: 0.9286 - lr: 0.0010\n","Epoch 7/7\n","401/401 [==============================] - 216s 538ms/step - loss: 0.1722 - accuracy: 0.9481 - val_loss: 0.1620 - val_accuracy: 0.9476 - lr: 0.0010\n"]}],"source":["import os\n","import shutil\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n","\n","# Define directories and constants\n","source_dir = dataset_path\n","train_dir = \"tomato/train\"\n","valid_dir = \"tomato/valid\"\n","BATCH_SIZE = 32\n","IMAGE_SHAPE = (224, 224)\n","numEPOCHS = 7  # You can increase the number of epochs\n","\n","# Data Augmentation\n","training_aug = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","testing_aug = ImageDataGenerator(rescale=1./255.0)\n","\n","# Load and preprocess data\n","training_data = training_aug.flow_from_directory(\n","    train_dir,\n","    batch_size=BATCH_SIZE,\n","    target_size=IMAGE_SHAPE,\n","    shuffle=True,\n","    class_mode='categorical'\n",")\n","\n","testing_data = testing_aug.flow_from_directory(\n","    valid_dir,\n","    batch_size=BATCH_SIZE,\n","    target_size=IMAGE_SHAPE,\n","    class_mode='categorical'\n",")\n","\n","# Define and compile the model\n","base_model = InceptionV3(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(224, 224, 3)\n",")\n","\n","model = keras.Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dense(512, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.5),\n","    Dense(CLASS_NUMS, activation='softmax')\n","])\n","\n","# Learning Rate Scheduler\n","def lr_scheduler(epoch):\n","    if epoch < 10:\n","        return 0.001\n","    else:\n","        return 0.0001\n","\n","lr_schedule = LearningRateScheduler(lr_scheduler)\n","\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Training with early stopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    restore_best_weights=True\n",")\n","\n","history = model.fit(\n","    training_data,\n","    validation_data=testing_data,\n","    epochs=numEPOCHS,\n","    steps_per_epoch=len(training_data),\n","    validation_steps=len(testing_data),\n","    callbacks=[early_stopping, lr_schedule]\n",")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"KtEH69b-51Oq","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9b3acd1c-e0a4-4a9e-ddaa-178bf6daa47f","executionInfo":{"status":"ok","timestamp":1708363399409,"user_tz":-330,"elapsed":1503,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["model.save(\"tomato_model.h5\")"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"9znM6Nxk54hC","executionInfo":{"status":"ok","timestamp":1708364340244,"user_tz":-330,"elapsed":63162,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[],"source":["from tensorflow import keras\n","import warnings\n","\n","#lodaing the trained model\n","warnings.filterwarnings(\"ignore\")\n","model = keras.models.load_model('tomato_model.h5')\n","\n","#converting model\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","#saving tflite model\n","with open('tomato.tflite', 'wb') as f:\n","    f.write(tflite_model)\n","\n","#creating interpreter for our model\n","interpreter = tf.lite.Interpreter(model_path='tomato.tflite')\n","interpreter.allocate_tensors()"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"dmUDvgleI-vA","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4b6725ff-56f6-46ea-bd3b-cfd03f25881a","executionInfo":{"status":"ok","timestamp":1708364340246,"user_tz":-330,"elapsed":102,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_049490ca-cdac-4cd1-85e5-e60b43e2d5cf\", \"tomato_model.h5\", 275203472)"]},"metadata":{}}],"source":["from google.colab import files\n","files.download(\"tomato_model.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jSutkk69Ol5F","executionInfo":{"status":"aborted","timestamp":1708359266518,"user_tz":-330,"elapsed":73,"user":{"displayName":"Akash Shetgar","userId":"00694055165224722721"}}},"outputs":[],"source":["#from google.colab import files\n","#files.download(\"tomato.tflite\")\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}