{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31908,"status":"ok","timestamp":1708410760269,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"},"user_tz":-330},"id":"1bzChom-4HXf","outputId":"e9fd6fe8-504c-4634-af07-eff872b26259"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1708410810071,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"},"user_tz":-330},"id":"79s-Fd4Y6j8f"},"outputs":[],"source":["# dataset_path = '/content/drive/MyDrive/Data Science and Analytics mini project/PlantVillage/PlantVillage/Pepper'\n","dataset_path = '/content/drive/MyDrive/LY 2023-24/SEM8/Data Science and Analytics mini project/PlantVillage/PlantVillage/Pepper'"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1708410811713,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"},"user_tz":-330},"id":"oorjqGtO5jTl"},"outputs":[],"source":["import os\n","from os import listdir\n","import matplotlib.pyplot as plt\n","import numpy as np"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":3607,"status":"ok","timestamp":1708410816062,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"},"user_tz":-330},"id":"ePjQkPiv5mp2"},"outputs":[],"source":["import tensorflow as tf\n","import os\n","import tensorflow.keras as keras\n","import re\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62115,"status":"ok","timestamp":1708410878173,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"},"user_tz":-330},"id":"2j-2wTxc5p_r","outputId":"e1a3d755-bc24-40d4-9468-ed71943ed2d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset split into training and validation sets.\n"]}],"source":["import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","\n","# Define the source directory containing your dataset\n","source_dir = dataset_path\n","\n","# Define the destination directories for training and validation data\n","train_dir = \"pepper/train\"\n","valid_dir = \"pepper/valid\"\n","\n","# Create the destination directories if they don't exist\n","os.makedirs(train_dir, exist_ok=True)\n","os.makedirs(valid_dir, exist_ok=True)\n","\n","# Get a list of class folders in the source directory\n","class_folders = os.listdir(source_dir)\n","\n","# Define the ratio of data to put in the validation set (e.g., 20%)\n","validation_ratio = 0.2\n","\n","# Loop through each class folder and split the data\n","for class_folder in class_folders:\n","    class_path = os.path.join(source_dir, class_folder)\n","    if os.path.isdir(class_path):\n","        images = os.listdir(class_path)\n","        # Split the images into training and validation sets\n","        train_images, valid_images = train_test_split(images, test_size=validation_ratio, random_state=42)\n","\n","        # Create destination directories for this class in the training and validation sets\n","        train_class_dir = os.path.join(train_dir, class_folder)\n","        valid_class_dir = os.path.join(valid_dir, class_folder)\n","        os.makedirs(train_class_dir, exist_ok=True)\n","        os.makedirs(valid_class_dir, exist_ok=True)\n","\n","        # Copy training images\n","        for image in train_images:\n","            source_image_path = os.path.join(class_path, image)\n","            dest_image_path = os.path.join(train_class_dir, image)\n","            shutil.copy(source_image_path, dest_image_path)\n","\n","        # Copy validation images\n","        for image in valid_images:\n","            source_image_path = os.path.join(class_path, image)\n","            dest_image_path = os.path.join(valid_class_dir, image)\n","            shutil.copy(source_image_path, dest_image_path)\n","\n","print(\"Dataset split into training and validation sets.\")"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1708410878173,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"},"user_tz":-330},"id":"_xsT6ZuC5tDq","outputId":"c56b0633-3a94-487a-c4f5-18637ce78a65"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of files in the training directory: 1979\n","Number of files in the validation directory: 496\n"]}],"source":["TRAIN_DIR = \"pepper/train\"\n","VALID_DIR = \"pepper/valid\"\n","def count_files_in_directory(directory):\n","    total_files = 0\n","    for root, dirs, files in os.walk(directory):\n","        total_files += len(files)\n","    return total_files\n","\n","num_train_files = count_files_in_directory(TRAIN_DIR)\n","num_valid_files = count_files_in_directory(VALID_DIR)\n","\n","print(\"Number of files in the training directory:\", num_train_files)\n","print(\"Number of files in the validation directory:\", num_valid_files)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1708410878174,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"},"user_tz":-330},"id":"TdnCPI0B5vgm","outputId":"7f8028d4-a1d6-4612-d60c-32db4cf3438e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes in the training directory: 2\n","Class names in the training directory:\n","Pepper__bell___Bacterial_spot\n","Pepper__bell___healthy\n"]}],"source":["TRAIN_DIR = \"pepper/train\"\n","\n","def get_classes_and_count(directory):\n","    classes = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n","    return classes, len(classes)\n","\n","class_names, CLASS_NUMS = get_classes_and_count(TRAIN_DIR)\n","\n","print(\"Number of classes in the training directory:\", CLASS_NUMS)\n","print(\"Class names in the training directory:\")\n","for class_name in class_names:\n","    print(class_name)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oZLyQK4cGGBY","executionInfo":{"status":"ok","timestamp":1708411179193,"user_tz":-330,"elapsed":301035,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"}},"outputId":"949db38b-f1dd-4a49-d376-5c8507430895"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 1979 images belonging to 2 classes.\n","Found 496 images belonging to 2 classes.\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 0s 0us/step\n","Epoch 1/7\n","62/62 [==============================] - 95s 692ms/step - loss: 0.2522 - accuracy: 0.9303 - val_loss: 17.2130 - val_accuracy: 0.5968 - lr: 0.0010\n","Epoch 2/7\n","62/62 [==============================] - 31s 508ms/step - loss: 0.0883 - accuracy: 0.9798 - val_loss: 0.0514 - val_accuracy: 0.9839 - lr: 0.0010\n","Epoch 3/7\n","62/62 [==============================] - 33s 528ms/step - loss: 0.0420 - accuracy: 0.9874 - val_loss: 0.2600 - val_accuracy: 0.9456 - lr: 0.0010\n","Epoch 4/7\n","62/62 [==============================] - 31s 500ms/step - loss: 0.0298 - accuracy: 0.9909 - val_loss: 0.2079 - val_accuracy: 0.9315 - lr: 0.0010\n","Epoch 5/7\n","62/62 [==============================] - 31s 501ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 0.0025 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 6/7\n","62/62 [==============================] - 32s 518ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0946 - val_accuracy: 0.9819 - lr: 0.0010\n","Epoch 7/7\n","62/62 [==============================] - 31s 505ms/step - loss: 0.0141 - accuracy: 0.9965 - val_loss: 5.3152e-04 - val_accuracy: 1.0000 - lr: 0.0010\n"]}],"source":["import os\n","import shutil\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications import InceptionV3\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n","\n","# Define directories and constants\n","source_dir = dataset_path\n","train_dir = \"pepper/train\"\n","valid_dir = \"pepper/valid\"\n","BATCH_SIZE = 32\n","IMAGE_SHAPE = (224, 224)\n","numEPOCHS = 7  # You can increase the number of epochs\n","\n","# Data Augmentation\n","training_aug = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=30,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","testing_aug = ImageDataGenerator(rescale=1./255.0)\n","\n","# Load and preprocess data\n","training_data = training_aug.flow_from_directory(\n","    train_dir,\n","    batch_size=BATCH_SIZE,\n","    target_size=IMAGE_SHAPE,\n","    shuffle=True,\n","    class_mode='categorical'\n",")\n","\n","testing_data = testing_aug.flow_from_directory(\n","    valid_dir,\n","    batch_size=BATCH_SIZE,\n","    target_size=IMAGE_SHAPE,\n","    class_mode='categorical'\n",")\n","\n","# Define and compile the model\n","base_model = InceptionV3(\n","    include_top=False,\n","    weights='imagenet',\n","    input_shape=(224, 224, 3)\n",")\n","\n","model = keras.Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dense(512, activation='relu'),\n","    BatchNormalization(),\n","    Dropout(0.5),\n","    Dense(CLASS_NUMS, activation='softmax')\n","])\n","\n","# Learning Rate Scheduler\n","def lr_scheduler(epoch):\n","    if epoch < 10:\n","        return 0.001\n","    else:\n","        return 0.0001\n","\n","lr_schedule = LearningRateScheduler(lr_scheduler)\n","\n","model.compile(\n","    optimizer=Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","# Training with early stopping\n","early_stopping = EarlyStopping(\n","    monitor='val_loss',\n","    patience=5,\n","    restore_best_weights=True\n",")\n","\n","history = model.fit(\n","    training_data,\n","    validation_data=testing_data,\n","    epochs=numEPOCHS,\n","    steps_per_epoch=len(training_data),\n","    validation_steps=len(testing_data),\n","    callbacks=[early_stopping, lr_schedule]\n",")\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"KtEH69b-51Oq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708412109341,"user_tz":-330,"elapsed":3586,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"}},"outputId":"6349dc06-e0c7-4ff7-a532-f9f6be550cef"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["model.save(\"pepper_model.h5\")"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"9znM6Nxk54hC","executionInfo":{"status":"ok","timestamp":1708412169487,"user_tz":-330,"elapsed":60148,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"}}},"outputs":[],"source":["from tensorflow import keras\n","import warnings\n","\n","#loading the trained model\n","warnings.filterwarnings(\"ignore\")\n","model = keras.models.load_model('pepper_model.h5')\n","\n","#converting model\n","converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = converter.convert()\n","\n","#saving tflite model\n","with open('pepper.tflite', 'wb') as f:\n","    f.write(tflite_model)\n","\n","#creating interpreter for our model\n","interpreter = tf.lite.Interpreter(model_path='pepper.tflite')\n","interpreter.allocate_tensors()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"dmUDvgleI-vA","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1708412169488,"user_tz":-330,"elapsed":108,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"}},"outputId":"782896d1-a4fc-421a-c5c4-87067cd2feb1"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_efd54d2a-c1ea-4476-abeb-c4a362e80d30\", \"pepper_model.h5\", 275154288)"]},"metadata":{}}],"source":["from google.colab import files\n","files.download(\"pepper_model.h5\")"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jSutkk69Ol5F","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1708412169492,"user_tz":-330,"elapsed":84,"user":{"displayName":"AAKASH WAGLE","userId":"14673769618098650602"}},"outputId":"48aa159f-cd73-4bcc-ba64-a8d9e68e31a3"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_7c729e63-b985-41c7-ae1b-b8868b02f921\", \"pepper.tflite\", 91336156)"]},"metadata":{}}],"source":["from google.colab import files\n","files.download(\"pepper.tflite\")"]},{"cell_type":"code","source":[],"metadata":{"id":"fLxYsirETADI"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}